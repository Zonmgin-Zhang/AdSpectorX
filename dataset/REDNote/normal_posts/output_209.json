{
    "title": "剑桥：LLM少量评测即可预测实际效果",
    "description": "📖标题：100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances\n🌐来源：arXiv, 2409.03563\n\n🛎️文章简介\n🔸研究问题：大语言模型（LLM）的评估通常需要在足够大的任务实例集上，是否能够减少评估次数？\n🔸主要贡献：论文提出了一种通过少量参考实例评估新LLM性能的框架，并展示了其在不同分布数据上的预测能力。\n\n📝重点思路\n🔺相关工作\n🔸AI系统的实例级预测：对于AI系统很重要，并引入了评估器模型，用于估计AI系统在个体实例上的成功概率。\n🔸LLM特征聚合的可预测性：使用LLM的信息如参数量或计算量，可以预测在特定基准的表现。\n🔸从现有评估中提取LLM特征：通过对不同基准上的各种LLM的表现进行建模推断，将复杂下游任务的表现与假设的能力维度关联。\n🔸通过基准二次采样预测性能：通过聚类模型的置信度对数据集进行二次采样，以预测整个数据集的整体准确性。\n🔸LLM推理评估：研究比较多，如GLoRE围绕多项选择、自然语言推理和二值答案，LogiGLUE围绕归纳、演绎和溯因等。\n\n🔺论文方案\n🔸研究目标：对于模型m，目标是训练一个分类器（评估器），能够根据提示p，预测m在p的表现。\n🔸主要思想：将测试数据集D分成不同的部分，用于训练、验证和评估评估器。\n🔸选择参考实例：围绕不同的内在特征选择和分类器家族及超参数优化，探讨了多种选择参考实例的方法。\n🔸训练通用评估器：通过在验证数据上训练，选择最佳的参考实例集和特征组合，构建一个通用的评估器，用于预测新LLM在新的实例上的性能。\n\n🔎分析总结\n🔸分布内：通用评估器的表现与特定评估器相当，甚至在某些情况下优于仅依赖于先前LLM信息或测试LLM在参考实例集上的结果的基线方法。\n🔸分布外：所有评估器的预测能力显著下降，表明LLM在分布外场景中的可预测性较低。\n🔸实例集选择：随机选择的参考实例集与高级选择方法表现相当，表明在某些情况下，简单的选择方法可能足够。\n\n💡个人观点\n论文主要是提供了一个概念说明，训练一个通用评估器的数据还是比较难做的，OOD效果也不是很好。\n\n#LLM  #大模型  #大模型评估  #论文分享  #剑桥  #涨知识",
    "date": "昨天 00:00 上海",
    "comments": [
        "这手速",
        "@momo"
    ],
    "image": [
        "1040g0k0317gs2hsugo005oellr3k0lkctkecgg8!nd_dft_wgth_webp_3_0.jpg",
        "1040g34o317gs2hqe3k0g5oellr3k0lkcbhu5tbo!nd_dft_wgth_webp_3_1.jpg"
    ],
    "label": 0
}